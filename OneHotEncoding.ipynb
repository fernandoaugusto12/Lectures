{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OneHotEncoding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sznajder/Lectures/blob/master/OneHotEncoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-mEC0CW5-Jv",
        "colab_type": "text"
      },
      "source": [
        "#CATEGORICAL DATA ENCODING\n",
        "\n",
        "**Machine learning algorithms cannot work with categorical data directly. Categorical data must be converted to numbers. This applies when you are working sequence classification problem using RNN(ex: LSTM, GRU) networks.**\n",
        "\n",
        "\n",
        " ( https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/ )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39gsZHGG7T06",
        "colab_type": "text"
      },
      "source": [
        "### **One Hot Encoding**\n",
        "\n",
        "A one hot encoding is a representation of categorical variables as binary vectors. This first requires that the categorical values be mapped to integer values. Then, each integer value is represented as a binary vector that is all zero values except the index of the integer, which is marked with a 1.\n",
        "\n",
        "This gives the network more expressive power to learn a **probability-like number for each possible label value(class)**, making the problem easier for the network to model. Also, when a one hot encoding is used for the output variable, it may offer a more nuanced set of predictions than a single label.\n",
        "\n",
        "As an example, consider a sequence of labels with the values ‘red’ , ‘green’ and 'blue'. We can assign ‘red’=0, ‘green’=1 aand 'blue=2.  A 1-1 mapping is important so that we can invert the encoding later and get labels back from integer values. Next, we can create a binary vector to represent each integer value.\n",
        "\n",
        "So, if we have a sequence:\n",
        "\n",
        "**'red', 'red', 'green', 'blue'**\n",
        "\n",
        "We can represent it with the integer encoding:\n",
        "\n",
        "**0, 0, 1, 2**\n",
        "\n",
        "The one hot encoding corresponds to the following representation:\n",
        "\n",
        "**[1,0,0], [1,0,0], [0,1,0], [0,0,1]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMfH-Mr68tG_",
        "colab_type": "text"
      },
      "source": [
        "**1) Manual One Hot Encoding:**\n",
        "In this example, we will assume the case where we have an example string of characters of alphabet letters. We will use the input sequence of the following characters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZoxSppO59EE",
        "colab_type": "code",
        "outputId": "959cf993-f9b9-443b-84b3-0c1282c5506e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from numpy import argmax\n",
        "# define input string\n",
        "data = 'hello world'\n",
        "print(data)\n",
        "print()\n",
        "# define universe of possible input values\n",
        "alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
        "# enumerate the alphabet\n",
        "print(list(enumerate(alphabet)))\n",
        "print()\n",
        "# define a mapping of chars to integers\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
        "# integer encode input data\n",
        "integer_encoded = [char_to_int[char] for char in data]\n",
        "print(integer_encoded)\n",
        "print()\n",
        "# one hot encode\n",
        "onehot_encoded = list()\n",
        "for value in integer_encoded:\n",
        "\tletter = [0 for _ in range(len(alphabet))]\n",
        "\tletter[value] = 1\n",
        "\tonehot_encoded.append(letter)\n",
        "print(onehot_encoded)\n",
        "# invert encoding\n",
        "inverted = int_to_char[argmax(onehot_encoded[0])]\n",
        "print(inverted)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello world\n",
            "\n",
            "[(0, 'a'), (1, 'b'), (2, 'c'), (3, 'd'), (4, 'e'), (5, 'f'), (6, 'g'), (7, 'h'), (8, 'i'), (9, 'j'), (10, 'k'), (11, 'l'), (12, 'm'), (13, 'n'), (14, 'o'), (15, 'p'), (16, 'q'), (17, 'r'), (18, 's'), (19, 't'), (20, 'u'), (21, 'v'), (22, 'w'), (23, 'x'), (24, 'y'), (25, 'z'), (26, ' ')]\n",
            "\n",
            "[7, 4, 11, 11, 14, 26, 22, 14, 17, 11, 3]\n",
            "\n",
            "[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD8raIWE9XeO",
        "colab_type": "text"
      },
      "source": [
        "**2) One Hot Encode with Scikit-Learn:**\n",
        "\n",
        "In this example, we will assume the case where you have an output sequence of the following 3 labels: \"cold\", \"warm\", \"hot\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fte0JrOS-UV-",
        "colab_type": "code",
        "outputId": "957e877d-fe77-451c-f17f-38f65ca0c345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# define example\n",
        "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
        "values = array(data)\n",
        "print(values)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm' 'cold' 'warm' 'hot']\n",
            "[0 0 2 0 1 1 2 0 2 1]\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n",
            "['cold']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXAfjLBIAjq8",
        "colab_type": "text"
      },
      "source": [
        "**3) One Hot Encode with Keras:**\n",
        "\n",
        "**You may have a sequence that is already integer encoded. The Keras library offers a function called to_categorical() that you can use to one hot encode integer data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5Ex9LgMEd27",
        "colab_type": "code",
        "outputId": "881a6354-81a0-43b5-f8a9-c17bd8214646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.utils import to_categorical\n",
        "# define example\n",
        "data = [1, 3, 2, 0, 3, 2, 2, 1, 0, 1]\n",
        "data = array(data)\n",
        "print(data)\n",
        "# one hot encode\n",
        "encoded = to_categorical(data)\n",
        "print(encoded)\n",
        "# invert encoding\n",
        "inverted = argmax(encoded[0])\n",
        "print(inverted)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1 3 2 0 3 2 2 1 0 1]\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}