{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OneHotEncoding.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"j-mEC0CW5-Jv","colab_type":"text"},"source":["#CATEGORICAL DATA ENCODING\n","\n","**Machine learning algorithms cannot work with categorical data directly. Categorical data must be converted to numbers. This applies when you are working with a sequence classification type problem and plan on using deep learning methods such as RNN(ex: LSTM, GRU) networks.**\n","\n","**You could work with the integers directly, after some scaling. Alternately, you can one hot encode the integers. This is important to consider if the integers do not have a real ordinal relationship (ex:'cold','warm','hot') and are really just placeholders for class labels.**\n","\n"," ( https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/ )"]},{"cell_type":"markdown","metadata":{"id":"39gsZHGG7T06","colab_type":"text"},"source":["### **One Hot Encoding**\n","\n","**A one hot encoding is a representation of categorical variables as binary vectors. This first requires that the categorical values be mapped to integer values. Then, each integer value is represented as a binary vector that is all zero values except the index of the integer, which is marked with a 1.**\n","\n","**This gives the network more expressive power to learn a probability-like number for each possible label value(class). This can help in both making the problem easier for the network to model. When a one hot encoding is used for the output variable, it may offer a more nuanced set of predictions than a single label.**\n","\n","**Assume we have a sequence of labels with the values ‘red’ and ‘green’.**\n","\n","**We can assign ‘red’ an integer value of 0 and ‘green’ the integer value of 1. As long as we always assign these numbers to these labels, this is called an integer encoding. A 1-1 mapping is important so that we can invert the encoding later and get labels back from integer values, such as in the case of making a prediction. Next, we can create a binary vector to represent each integer value.**\n","\n","**So, if we had the sequence:**\n","\n","'red', 'red', 'green'\n","\n","**We could represent it with the integer encoding:**\n","\n","0, 0, 1\n","\n","**And the one hot encoding:**\n","\n","[1, 0]\n","\n","[1, 0]\n","\n","[0, 1]\n"]},{"cell_type":"markdown","metadata":{"id":"LMfH-Mr68tG_","colab_type":"text"},"source":["**1) Manual One Hot Encoding:**\n","\n","**In this example, we will assume the case where we have an example string of characters of alphabet letters. We will use the input sequence of the following characters:**"]},{"cell_type":"code","metadata":{"id":"lZoxSppO59EE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"3aa1b730-d074-4736-9cff-05c1c2593a5a","executionInfo":{"status":"ok","timestamp":1570282125472,"user_tz":180,"elapsed":1152,"user":{"displayName":"Andre Sznajder","photoUrl":"https://lh3.googleusercontent.com/-Bujzmul3q4w/AAAAAAAAAAI/AAAAAAAAA30/Zzdg4zcPB-8/s64/photo.jpg","userId":"12562331206892861623"}}},"source":["from numpy import argmax\n","# define input string\n","data = 'hello world'\n","print(data)\n","print()\n","# define universe of possible input values\n","alphabet = 'abcdefghijklmnopqrstuvwxyz '\n","# enumerate the alphabet\n","print(list(enumerate(alphabet)))\n","print()\n","# define a mapping of chars to integers\n","char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n","int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n","# integer encode input data\n","integer_encoded = [char_to_int[char] for char in data]\n","print(integer_encoded)\n","print()\n","# one hot encode\n","onehot_encoded = list()\n","for value in integer_encoded:\n","\tletter = [0 for _ in range(len(alphabet))]\n","\tletter[value] = 1\n","\tonehot_encoded.append(letter)\n","print(onehot_encoded)\n","# invert encoding\n","inverted = int_to_char[argmax(onehot_encoded[0])]\n","print(inverted)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["hello world\n","\n","[(0, 'a'), (1, 'b'), (2, 'c'), (3, 'd'), (4, 'e'), (5, 'f'), (6, 'g'), (7, 'h'), (8, 'i'), (9, 'j'), (10, 'k'), (11, 'l'), (12, 'm'), (13, 'n'), (14, 'o'), (15, 'p'), (16, 'q'), (17, 'r'), (18, 's'), (19, 't'), (20, 'u'), (21, 'v'), (22, 'w'), (23, 'x'), (24, 'y'), (25, 'z'), (26, ' ')]\n","\n","[7, 4, 11, 11, 14, 26, 22, 14, 17, 11, 3]\n","\n","[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n","h\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GD8raIWE9XeO","colab_type":"text"},"source":["**2) One Hot Encode with Scikit-Learn:**\n","\n","**In this example, we will assume the case where you have an output sequence of the following 3 labels: \"cold\", \"warm\", \"hot\"**"]},{"cell_type":"code","metadata":{"id":"Fte0JrOS-UV-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"outputId":"957e877d-fe77-451c-f17f-38f65ca0c345","executionInfo":{"status":"ok","timestamp":1570281543677,"user_tz":180,"elapsed":2143,"user":{"displayName":"Andre Sznajder","photoUrl":"https://lh3.googleusercontent.com/-Bujzmul3q4w/AAAAAAAAAAI/AAAAAAAAA30/Zzdg4zcPB-8/s64/photo.jpg","userId":"12562331206892861623"}}},"source":["from numpy import array\n","from numpy import argmax\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","# define example\n","data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n","values = array(data)\n","print(values)\n","# integer encode\n","label_encoder = LabelEncoder()\n","integer_encoded = label_encoder.fit_transform(values)\n","print(integer_encoded)\n","# binary encode\n","onehot_encoder = OneHotEncoder(sparse=False)\n","integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","print(onehot_encoded)\n","# invert first example\n","inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n","print(inverted)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm' 'cold' 'warm' 'hot']\n","[0 0 2 0 1 1 2 0 2 1]\n","[[1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]]\n","['cold']\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n","If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n","In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n","  warnings.warn(msg, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"QXAfjLBIAjq8","colab_type":"text"},"source":["**3) One Hot Encode with Keras:**\n","\n","**You may have a sequence that is already integer encoded. The Keras library offers a function called to_categorical() that you can use to one hot encode integer data.**"]},{"cell_type":"code","metadata":{"id":"b5Ex9LgMEd27","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"881a6354-81a0-43b5-f8a9-c17bd8214646","executionInfo":{"status":"ok","timestamp":1570281545993,"user_tz":180,"elapsed":4456,"user":{"displayName":"Andre Sznajder","photoUrl":"https://lh3.googleusercontent.com/-Bujzmul3q4w/AAAAAAAAAAI/AAAAAAAAA30/Zzdg4zcPB-8/s64/photo.jpg","userId":"12562331206892861623"}}},"source":["from numpy import array\n","from numpy import argmax\n","from keras.utils import to_categorical\n","# define example\n","data = [1, 3, 2, 0, 3, 2, 2, 1, 0, 1]\n","data = array(data)\n","print(data)\n","# one hot encode\n","encoded = to_categorical(data)\n","print(encoded)\n","# invert encoding\n","inverted = argmax(encoded[0])\n","print(inverted)\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["[1 3 2 0 3 2 2 1 0 1]\n","[[0. 1. 0. 0.]\n"," [0. 0. 0. 1.]\n"," [0. 0. 1. 0.]\n"," [1. 0. 0. 0.]\n"," [0. 0. 0. 1.]\n"," [0. 0. 1. 0.]\n"," [0. 0. 1. 0.]\n"," [0. 1. 0. 0.]\n"," [1. 0. 0. 0.]\n"," [0. 1. 0. 0.]]\n","1\n"],"name":"stdout"}]}]}