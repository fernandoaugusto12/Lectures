{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP_MNIST_Keras.ipynb","provenance":[{"file_id":"https://github.com/sznajder/Bari_Lectures/blob/master/NotebooksAndScripts/MLP_Keras_tutorial.ipynb","timestamp":1551793294889}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ftxVZMcL9zlw","colab_type":"text"},"source":["**JUPYTER NOTEBOOK FOR A MLP LEARNING MNIST NUMBERS from 0 to 9 **"]},{"cell_type":"code","metadata":{"id":"h1MQaRXWLVxm","colab_type":"code","outputId":"16a45a52-1723-449d-f3e7-6911f3f0d4d0","executionInfo":{"status":"ok","timestamp":1569254882715,"user_tz":180,"elapsed":2053,"user":{"displayName":"Andre Sznajder","photoUrl":"https://lh3.googleusercontent.com/-Bujzmul3q4w/AAAAAAAAAAI/AAAAAAAAA30/Zzdg4zcPB-8/s64/photo.jpg","userId":"12562331206892861623"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import SGD\n","from keras.datasets import mnist\n","from keras.utils import np_utils"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"yvoxEUZsXSpp","colab_type":"text"},"source":["**Define the network hyperparameters**"]},{"cell_type":"code","metadata":{"id":"Oo7CQ7KkFSud","colab_type":"code","colab":{}},"source":["# Trainign batch size \n","batch_size = 100\n","# Number of training epochs\n","epochs = 50\n","# Fraction of the training data to be used as validation\n","val_split = 0.3\n","# Learning rate\n","lr=0.05\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VA0a8nUbXes8","colab_type":"text"},"source":["**Load the MNIST dataset and format it for train and validation**"]},{"cell_type":"code","metadata":{"id":"vwHyt7p9FSun","colab_type":"code","outputId":"ac670bc4-7836-4ab5-fd84-b4347b64dc7d","executionInfo":{"status":"ok","timestamp":1569254888670,"user_tz":180,"elapsed":7992,"user":{"displayName":"Andre Sznajder","photoUrl":"https://lh3.googleusercontent.com/-Bujzmul3q4w/AAAAAAAAAAI/AAAAAAAAA30/Zzdg4zcPB-8/s64/photo.jpg","userId":"12562331206892861623"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Load MNIST dataset (28x28 pixel images)\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = X_train.reshape(60000, 784)\n","X_test = X_test.reshape(10000, 784)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","Y_Train = y_train/10.\n","print(y_test)\n","Y_Test = y_test/10.\n","print(Y_Test)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","[7 2 1 ... 4 5 6]\n","[0.7 0.2 0.1 ... 0.4 0.5 0.6]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bW5Ef_8PXtYs","colab_type":"text"},"source":["**Define the MLP achitecture using KERAS sequential API**"]},{"cell_type":"code","metadata":{"id":"vnEXAUWpFSus","colab_type":"code","outputId":"554a6476-d480-41ec-a2ac-f108cd836c7e","executionInfo":{"status":"ok","timestamp":1569254888869,"user_tz":180,"elapsed":8180,"user":{"displayName":"Andre Sznajder","photoUrl":"https://lh3.googleusercontent.com/-Bujzmul3q4w/AAAAAAAAAAI/AAAAAAAAA30/Zzdg4zcPB-8/s64/photo.jpg","userId":"12562331206892861623"}},"colab":{"base_uri":"https://localhost:8080/","height":445}},"source":["# Multilayer Perceptron model\n","model = Sequential()\n","model.add(Dense(input_dim=784, activation=\"relu\", units=100, kernel_initializer=\"normal\"))\n","model.add(Dense(activation=\"relu\", units=50, kernel_initializer=\"normal\")) # after first layer no need to specify input_dim\n","model.add(Dense(activation=\"relu\", units=25, kernel_initializer=\"normal\")) # after first layer no need to specify input_dim\n","model.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"normal\"))\n","model.compile(optimizer=SGD(lr=lr), loss='mean_squared_error', metrics=['accuracy'])\n","model.summary()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 100)               78500     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 50)                5050      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 25)                1275      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 26        \n","=================================================================\n","Total params: 84,851\n","Trainable params: 84,851\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R1Uju_bZX45K","colab_type":"text"},"source":["**Train the MLP**"]},{"cell_type":"code","metadata":{"id":"v1ZdRrtvFSu3","colab_type":"code","outputId":"b9143402-de18-4d5b-b019-969114cd32b1","executionInfo":{"status":"error","timestamp":1569254891632,"user_tz":180,"elapsed":10932,"user":{"displayName":"Andre Sznajder","photoUrl":"https://lh3.googleusercontent.com/-Bujzmul3q4w/AAAAAAAAAAI/AAAAAAAAA30/Zzdg4zcPB-8/s64/photo.jpg","userId":"12562331206892861623"}},"colab":{"base_uri":"https://localhost:8080/","height":480}},"source":["# Train\n","history = model.fit(X_train, Y_Train, validation_split=val_split, epochs=epochs, batch_size=batch_size, verbose=1)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Train on 42000 samples, validate on 18000 samples\n","Epoch 1/50\n","42000/42000 [==============================] - 2s 51us/step - loss: 0.0837 - acc: 0.0969 - val_loss: 0.0821 - val_acc: 0.0989\n","Epoch 2/50\n"," 3600/42000 [=>............................] - ETA: 1s - loss: 0.0844 - acc: 0.0994"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-0cf4ca549846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"87neTyT0X-1f","colab_type":"text"},"source":["**Evaluate the MLP performance**"]},{"cell_type":"code","metadata":{"id":"tOlt7lO3FSvA","colab_type":"code","colab":{}},"source":["# Evaluate\n","evaluation = model.evaluate(X_test, Y_Test, verbose=1)\n","print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bEmgseziYHhS","colab_type":"text"},"source":["**Plot the training and validation performances**"]},{"cell_type":"code","metadata":{"id":"2kdXNm_WFbME","colab_type":"code","colab":{}},"source":["# Training History Visualization\n","\n","# Plot training & validation accuracy values\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()\n","\n","# Plot training & validation loss values\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper right')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"54xIi0GPrGNB","colab_type":"code","colab":{}},"source":["Nplot = 20\n","plt.figure(figsize=(10,10))\n","Y=model.predict(X_test) \n","Y=Y*10.\n","for n in range(Nplot):\n","  X=X_test[n,:]\n","  ax = plt.subplot(4, 5, n+1)\n","  plt.imshow(X.reshape(28,28))\n","  plt.axis('off')\n","  plt.title('Prediction='+str(round(float(Y[n]))))\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4agGtlXb755a","colab_type":"text"},"source":["**Exercises:**\n","\n","---\n","\n","\n","**Question 1**: What happens if you increase/decrease the number of hidden layers?\n","\n","\n","**Question 2:** What happens if you increase/decrease the number of nodes per hidden layer?\n","\n","**Question 3:** What happens if you increase/decrease the learning rate ?\n","\n","**Question 4:** What happens if you increase/decrease the number of training epochs  ?\n","\n","**Question 5:** What happens if you increase/decrease the training batch size ?\n","\n","**Question 6:** What happens if you use the ReLU activation function in the hidden layers ?"]}]}